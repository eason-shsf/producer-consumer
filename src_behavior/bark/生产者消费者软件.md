[TOC]
# 软件中的生产者消费者  

# 软件中的生产者消费者概述  
在上节课程中，生产者/消费者/缓冲器都是一个模块，并未涉及如何实现。那么软件中，这些模块该如何实现呢?  
本节将阐述生产者消费者模式在软件中的实现思路和实现的代码。在基本实现的基础上，本节将继续围绕概述一章中提到的缓冲区深度控制、竞争、缓冲区结构三个问题，分别进行阐述并提供解决上述问题的代码示例，通过逐渐深入、代码和文字结合的方式，逐渐讲明生产者模型在软件中的实现。  
本小节不涉及具体实现，重点介绍软件实现中涉及到的几个知识点，包括多线程和并发、软件中的生产者消费者模式、操作系统中断、python（本节软件实现示例均为python编写，读者可举一反三，采用C等语言做实现，加深理解）
## 并发和并行
### 并发
![concurrency.jpg](D:\coding\python\pythonVscode\images\concurrency.jpg)
* Concurrency，是并发的意思。并发的实质是一个物理CPU(也可以多个物理CPU) 在若干道程序（或线程）之间多路复用，并发性是对有限物理资源强制行使多用户共享以提高效率。
* 微观角度：所有的并发处理都有排队等候，唤醒，执行等这样的步骤，在微观上他们都是序列被处理的，如果是同一时刻到达的请求（或线程）也会根据优先级的不同，而先后进入队列排队等候执行。
* 宏观角度：多个几乎同时到达的请求（或线程）在宏观上看就像是同时在被处理。
* 通俗点讲，并发就是只有一个CPU资源，程序（或线程）之间要竞争得到执行机会。图中的第一个阶段，在A执行的过程中B，C不会执行，因为这段时间内这个CPU资源被A竞争到了，同理，第二个阶段只有B在执行，第三个阶段只有C在执行。其实，并发过程中，A，B，C并不是同时在进行的（微观角度）。但又是同时进行的（宏观角度）。
### 并行
![parallelism.jpg](D:\coding\python\pythonVscode\images\parallelism.jpg)
* Parallelism，即并行，指两个或两个以上事件（或线程）在同一时刻发生，是真正意义上的不同事件或线程在同一时刻，在不同CPU资源呢上（多核），同时执行。
* 并行，不存在像并发那样竞争，等待的概念。
* 图中，A，B，C都在同时运行（微观，宏观）。  
## 多进程和多线程  
首先介绍一下进程和线程的概念。  
进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。简单点说，进程就是执行中的程序活动，是一个活动的实体，而且具有独立性不与其他进程共享内存。  
线程，是一个执行中的程序活动（即进程）的多个执行路径，执行调度的单位。线程依托于进程存在，在进程之下，可以共享进程的内存，而且还拥有一个属于自己的内存空间，这段内存空间也叫做线程栈，是在建立线程时由系统分配的，主要用来保存线程内部所使用的数据。    
在理解了线程和进程的概念之后，再来看多进程和多线程。  
多进程就是一台计算机可以同时执行多个独立的程序运行活动，这个比较好理解，各个运行活动之间是相互独立的。  
多线程则是指每个进程内部，又可以划分出多个并行（或并发）执行的任务，这些任务就是线程。线程与进程的区别体现在线程之间共享了同一个进程的内存空间，相互关联性强。  
本节实现生产者消费者模式将基于多线程实现，在此以多线程为例，讲解一下多线程多进程和并行、并发之间的关系。  
上面已经阐述了并发实际上同一时间只在执行一个任务，通过在多个任务间切换执行的方式实现多个“同时执行”的效果；并行则是真正多个同时执行，不会相互等待；多线程实际上就是设置了多个可以“同时”执行的线程，在不竞争访问内存的前提下，多个线程也是独立的，这时候多线程是并行还是并发其实取决于线程的CPU划分，如果进程内的多个线程划分了1个CPU，那么多线程只能分片获取CPU执行时间，只能是并发；反之每个线程拥有独立的CPU，则可以并行执行，互不干扰。   
在此需要指出的是python的threading模块实现的多线程只支持使用一个CPU，即只支持并发模式。
当通过并发的方式实现多线程的时候，CPU需要切换正在执行的线程，也就是需要定时器或其他机制出发中断，暂停当前任务，执行新的任务。由于中断是由线程外部的机制（操作系统和定时器）控制的，线程A执行到任何位置都可能被突然挂起，然后执行线程B一段时间后又被恢复，由于线程B和A共享内存，极可能线程B的操作会对线程A产生预料之外的影响，这就是中断带来的问题，也可以说是竞争问题，这也是生产者消费者实现面临的最重要的问题。
## 软件中生产者消费者类型划分    
按照生产者消费者的数目划分为单生产者单消费者、单生产者多消费者、多生产者单消费者、多生产者多消费者。  

## python  
本节代码示例采用python语言开发。python近年来发展十分迅速，尤其在数据科学和机器学习领域应用十分广泛。  
Python的哲学就是简单优雅，尽量写容易看明白的代码，尽量写少的代码。Python为我们提供了非常完善的基础代码库，覆盖了网络、文件、GUI、数据库、文本等大量内容。Python吸引了各个领域的公司和开发者投入python，为我们带来了大量的第三方库，可以说python是非常有学习价值的。  
如果没有接触过Python的同学，可以在看本文示例过程中再看一个python入门教程学习python，相信会有额外的收获。  
代码示例采用的python代码均在python3.6上进行调试，语法和python2.7有所不同。  
另外本节采用的是python 多线程方式来讲述生产者消费者模型，课程除了python基本语法，使用的主要是python的threading module里的内容，包括Thread、Lock、RLock、Event、Semaphore、Condition等类，该模块在python官方教程的如下链接：  https://docs.python.org/3/library/threading.html。  
# 软件中的生产者消费者原理和python实现
## 软件中的生产者消费者实现机制
前面的章节已经阐述了生产者消费者模式的基本原理，我们看到生产者消费者模式主要需要三个部分:生产者、消费者、缓冲区。    
软件开发中的生产者消费者模型通过多线程或者多进程机制实现。
对于多线程方式的生产者消费者模型，每个生产者和消费者都是同一个进程下的一个线程，线程间共享内存空间，多个线程可以直接访问共享内存中的缓冲区。缓冲区数据结构可以是数组或链表，一般由该进程的主线程新建和管理，生产者和消费者按照规则有序访问。  
针对多进程机制的生产者消费者模式，每个生产者和消费者都是一个独立的进程，每个进程拥有独立的内存空间，进程间通信可以通过管道进行，操作缓冲区比多线程方式有些复杂。缓冲区同样可以是链表或数组形式的数据结构，但缓冲区应当由另外一个独立的进程进行管理，不属于生产者或消费者进程，生产者和消费者通过一定的约定有序访问缓冲区。   
缓冲区的类型包括队列缓冲区、环形缓冲区和双缓冲区等，队列缓冲区可以直接用数组实现，环形缓冲区可以考虑使用数组或链表，双缓冲区需要采用双数组并添加逻辑控制，在缓冲区满和缓冲区空的时候进行切换。  
## 实现的代码及讲解  
在对实现机制基本介绍的基础上，本小节将实现一个基本的生产者消费者模型，在此基础上通过代码实际运行指出基本模型会发现的一些问题，并在后续过程中提供改进这些问题的解决方法和示例代码，最终提供几种具有实用性的生产者消费者模式示例代码。  
本节代码全部通过python实现，实现基于多线程模式。  
基本的多线程生产者消费者模式的实现如下所示，为充分模拟操作系统生产者消费者实现机制，代码中的缓冲区是通过一个定长度的数组和两个表示读写标志位的变量结合来模拟的，因此写入数据并非给数组append数据，而是给数组某个位置的数据赋值并给标志位加1；读取数据也不是pop数据，而是从数组某个位置读取当前值，并给标志位加1，具体如下所示：  
```python
# coding=utf-8
import time
import threading
from random import randint


TIMEOUT = 200


def consumer():
    t = threading.current_thread()
    global arr
    global readPos
    while 1:
        time.sleep(2)
        curValue = arr[readPos]
        print('{} popped from list by {}, read position: {}'.format(
            curValue, t.name, readPos))
        readPos += 1


def producer():
    t = threading.current_thread()
    global arr
    global writePos
    while 1:
        time.sleep(1)
        integer = randint(10, 100)
        arr[writePos] = integer
        print('{} appended to list by {}, writePosition: {}'.format(
            integer, t.name, writePos))
        writePos += 1


stackLength = 10
arr = [0]*stackLength
threads = []
readPos = 0
writePos = 0

t = threading.Thread(name="consumer", target=consumer)
t.daemon = True
t.start()
threads.append(t)

p = threading.Thread(name='pro', target=producer)
p.daemon = True
p.start()
threads.append(p)

time.sleep(100)
```
首先主线程定义了两个方法，一个consumer是消费者，一个producer是生产者。消费者每隔2s从全局list arr中取出一个值，并把值打印在控制台上。生产者每隔1s生成一个随机数，把随机数加入到全局数组，并打印该数。  
然后主线程定义了一个list作为简单的缓冲区，然后调用threading.Thread依次用上述两个方法分别构造了一个消费者线程，一个生产者线程，并启动这两个子线程。  
这样一个基本的生产者消费者模型就构造完成了，运行后控制台打印出如下结果：
```python
89 appended to list by pro, writePosition: 0
endings...

98 appended to list by pro, writePosition: 1
0 popped from list by consumer, read position: 0
11 appended to list by pro, writePosition: 2
64 appended to list by pro, writePosition: 3
98 popped from list by consumer, read position: 1
12 appended to list by pro, writePosition: 4
62 appended to list by pro, writePosition: 5
```
可以看到生产者会定时生产一个随机数，并把数放入缓冲区的位置并给指针加1，消费者会定时从当前读取指针位置读取一个随机数，并把读取指针加1，生产者消费者之间由于缓冲区的存在实现了解耦，生产者比消费者快时并不需要等待生产者，只需将数据放入缓冲区中，从而实现了基本的生产者消费者模型。
## 缓冲区结构、堆栈深度控制和竞争  
我们在上面基本模型的基础上继续分析，生产者生产随机数间隔1s，消费者读取随机数间隔2s，两个线程并发执行，由于间隔时间不同，生产比消费快一倍。可以看到每隔2s，数组arr的写入位置和读出位置的指针位置在逐步扩大。  
从这个模型和上面的阐述中我们发现一个问题：当前的缓冲区是队列缓冲区，随着生产者不断生产，写入指针的数值不断扩大，直到当前数组的尽头（长度10）之后就会溢出报错，溢出的报错如下所示：  
```python
37 popped from list by consumer, read position: 4
Exception in thread pro:
Traceback (most recent call last):
  File "D:\ProgramInstall\python3_6_5\lib\threading.py", line 916, in _bootstrap_inner
    self.run()
  File "D:\ProgramInstall\python3_6_5\lib\threading.py", line 864, in run
    self._target(*self._args, **self._kwargs)
  File "d:\coding\python\pythonVscode\simple_pro_cons_basic.py",
line 41, in producer
    arr[writePos] = integer
IndexError: list assignment index out of range
```
其实此时读取位置已经到了4,1-4的位置已经可以重复利用了，整个队列并没有真正发生溢出，这就是线性缓冲区的结构问题，可以引入环形缓冲区和双缓冲区解决。在此可以在上述代码中加入如下函数，使用这个函数进行read position和write position两个指针的计算：  
```python
def countPosition(pos):
    global stackLength
    if pos < stackLength - 1:
        pos = pos + 1
    else:
        pos = 0
    return pos
```
这样在读取和写入到达缓冲区大小上限后会重新回到起点去读取和写入，模拟实现了一个环形缓冲区，解决了上述问题，效果如下所示： 
```python
80 appended to list by pro, writePosition: 9
51 popped from list by consumer, read position: 4
20 appended to list by pro, writePosition: 0
```
使用环形缓冲区后，我们继续看还有没有其他问题。      
首先，上述代码不断运行过程中，我们看到写入指针更快的到9回0，随后在读取指针在8的时候再次超过读取指针，再次在9写入，如下所示：    
```python
12 appended to list by pro, writePosition: 9
15 popped from list by consumer, read position: 4
71 appended to list by pro, writePosition: 0
48 appended to list by pro, writePosition: 1
49 popped from list by consumer, read position: 5
64 appended to list by pro, writePosition: 2
44 appended to list by pro, writePosition: 3
64 popped from list by consumer, read position: 6
96 appended to list by pro, writePosition: 4
59 appended to list by pro, writePosition: 5
33 popped from list by consumer, read position: 7
78 appended to list by pro, writePosition: 6
19 appended to list by pro, writePosition: 7
41 popped from list by consumer, read position: 8
17 appended to list by pro, writePosition: 8
21 appended to list by pro, writePosition: 9
```
此时上次在位置9写入的内容还未读取就被覆盖了，由于堆栈深度无法满足读取写入状态的持续，导致了缓冲区真正的溢出，需要采用手段对缓冲区深度进行控制。当然还有另一种情况就是读取速度快于写入速度，情况和前者类似，在此不展开描述。  
另一个问题就是可能出现的竞争问题，就是多个生产者消费者线程之间可能由于并发原因竞争操作主线程中的变量，从而造成对缓冲区或者缓冲区指针变量的访问出现冲突，造成重复写入读取某个缓冲区的值或者跳过某个缓冲区的值的问题。
例如我们将消费者改成2个，如下所示把原来的这段代码：
```python
t = threading.Thread(name="consumer", target=consumer)
t.daemon = True
t.start()
threads.append(t)
```
改为： 
```python
t = threading.Thread(name="consumer1", target=consumer)
t.daemon = True
t.start()
threads.append(t)

t = threading.Thread(name="consumer2", target=consumer)
t.daemon = True
t.start()
threads.append(t)
```
运行代码，发现其中有几次两个消费者线程读取了同一个值，并跳过了下一个值：  
```python
5 appended to list by pro, writePosition: 0
75 popped from list by consumer1, read position: 0
75 popped from list by consumer2, read position: 0
34 appended to list by pro, writePosition: 1
11 appended to list by pro, writePosition: 2
11 popped from list by consumer1, read position: 211 popped from list by consumer2, read position: 2

48 appended to list by pro, writePosition: 3
60 appended to list by pro, writePosition: 4
60 popped from list by consumer1, read position: 4
0 popped from list by consumer2, read position: 5
```
造成这个的原因就是上述的竞争，源于其中一个消费者A线程在读取当前要读取的数据之后没有继续运行，被CPU中断后挂起，此时另一个读取进程B被运行，读取到了同一个位置的同一个值，造成这个值被重复处理。随后回到A自增读取指针，然后sleep，再次切换到B，B为读取指针自增，B sleep，再次回到A时读取指针已经被自增了2次，导致下一个值被跳过。  
竞争问题是生产者消费者模式面临的重要问题，这只是一种竞争发生的场景，后续的主要部分均为对解决竞争问题的方法的介绍。  

# 缓冲区深度控制方案  
第二小节中发现了两个问题，其中一个就是在缓冲区写入速度比读取速度快的时候，最终缓冲区会写入还没有被读取的数据位，造成溢出效应；其实反过来如果读取速度快于写入速度，可以想到一段时间之后，读取线程会重复读取刚刚读过的数据，造成重复处理。  
## 缓冲区深度控制可以考虑的方向  
上述问题可以看成是缓冲区深度设计问题。那么我们应该如何解决缓冲区深度问题呢？这里介绍两个方法。
第一是对缓冲区的长度进行合理的设计，即通过算法计算多个生产者总体的生产速度对时间的积分减去消费者总体读取速度对时间的积分，这个积分差的最大值就是缓冲区所需的长度（具体可以参照第一章概述中水池排水的举例）。如果比这个长度短，就会出现溢出效应，如果比这个长度更长，就会造成对内存的浪费。  
当然，对于上面这个代码示例来说，由于生产者一直比消费者快，随着时间的推移，这个积分差会变得无限大，这个方法不可行。我们可以合理设置生产者消费者数量的比例（在本例中为1:2）或者修改生产者消费者的代码实现，使实际运行的生产者消费者能够使用这个方法。  
第二是通过缓冲区读写两个标志位的值进行判断，在读取位要超圈（针对环形缓冲区）写入位或写入位即将超圈读取位的时候，阻止继续的读取或写入，比如可以强制生产者或消费者睡眠。这样就能确保不会出现缓冲区深度不足带来的问题，让生产者消费者模型持续运行。  
这个方法也有他的缺点，就是生产者或消费者会周期性的sleep，降低了生产者和消费者整体的效率。
## 缓冲区读写标志位判断法
下面通过改造一下上述代码，介绍一下如何通过缓冲区标志位的判断实现缓冲区深度控制：  
```python
# coding=utf-8
import time
import threading
from random import randint


TIMEOUT = 200


def consumer():
    t = threading.current_thread()
    global arr
    global readPos
    global onSameRound
    while 1:
        time.sleep(2)
        curValue = arr[readPos]
        print('{} popped from list by {}, read position: {}'.format(
            curValue, t.name, readPos))
        readPos = countPosition(readPos)
        while onSameRound and readPos >= writePos:
            time.sleep(1)


def producer():
    t = threading.current_thread()
    global arr
    global writePos
    global onSameRound
    while 1:
        time.sleep(1)
        integer = randint(10, 100)
        arr[writePos] = integer
        print('{} appended to list by {}, writePosition: {}'.format(
            integer, t.name, writePos))
        writePos = countPosition(writePos)
        while not onSameRound and writePos >= readPos:
            time.sleep(1)


def countPosition(pos):
    global stackLength
    global onSameRound
    if pos < stackLength - 1:
        pos = pos + 1
    else:
        pos = 0
        onSameRound = not onSameRound
    return pos


stackLength = 10
arr = [0]*stackLength
threads = []
readPos = 0
writePos = 0
onSameRound = True

t = threading.Thread(name="consumer", target=consumer)
t.daemon = True
t.start()
threads.append(t)

p = threading.Thread(name='pro', target=producer)
p.daemon = True
p.start()
threads.append(p)

time.sleep(100)
```
为方便继续讲解，在此贴出堆栈控制方案的完整代码。  
上述代码根据环形缓冲区的特点设置了对应的标志位控制方案。首先增加了一个onSameRound的global变量，声明在主线程当中。这个变量在生产者或消费者进程的位置指针（readPos/writePos）加1的时候会进行判断，记录readPos和writePos是否在同一个圈上，如果生产者线程已经超圈则为false，还在一个圈则为true（注意标志位控制会保证消费者的读取指针readPos不会超过生产者的writePos，也就不可能超圈生产者进程）。  
当消费者线程运行一次并给readPos加1后，添加了额外的判断逻辑：如果onSameRound为true并且readPos 大于等于（合理情况下只会等于）writePos时，保持消费者为睡眠状态，这样确保读取进程永远不会超过写入线程的WritePos，不会出现重复读取；已被超圈情况下则不需要控制消费者睡眠。
当生产者线程运行一次并给writePos加1后，会判断当onSameRound为false时，已经超圈消费者，在writePos >= readPos（合理情况下只会等于）时，保持生产者睡眠状态，不允许覆写还没有读取的内存地址，保证不会出现缓冲区溢出；未超圈情况下不需要控制生产者。  
上述代码实际执行结果如下所示：  
```python
21 popped from list by consumer, read position: 6
40 appended to list by pro, writePosition: 4
56 appended to list by pro, writePosition: 5
40 popped from list by consumer, read position: 7
44 appended to list by pro, writePosition: 6
57 appended to list by pro, writePosition: 7
89 popped from list by consumer, read position: 8
57 appended to list by pro, writePosition: 8
73 popped from list by consumer, read position: 9
91 appended to list by pro, writePosition: 9
89 popped from list by consumer, read position: 0
```
截取的片段为生产者已经超圈消费者之后的情况，可以看到当生产者已经读到消费者还未读取的位置，不再超过消费者的位置，说明每隔1s都会sleep 1，不会出现溢出。  
# 竞争的解决办法
## 竞争问题概述  
回顾一下上面两个消费者的情况，就是由于消费者在读取数据和给读取指针加1的操作之间被中断，造成另一个消费者线程拿到的指针出现了重复，造成了竞争。  
在多线程中，当两个或以上的线程对同一个数据进行操作的时候，可能会产生“竞争条件”的现象。这种现象产生的根本原因是因为多个线程在对同一个数据进行操作，此时对该数据的操作是非“原子化”的，可能前一个线程对数据的操作还没有结束，后一个线程又开始对同样的数据开始进行操作，这就可能会造成数据结果的变化未知。   
具体到生产者消费者模式中，我们来看看在哪些地方对数据或者说同一个内存地址进行同时访问会造成竞争问题，首先来回顾一下生产者和消费者在一次读写操作中都做了什么：  
生产者：  
1. 读取readPos, writePos值
1. 根据readPos与writePos判断是否为已写满整个缓冲区，若满则等待一段时间并，回到1步，继续执行
1. 若缓冲区不满，生产者将数据放进缓冲区
1. 生产者修改writePos

消费者： 
1. 读取readPos, writePos值
1. 根据readPos与writePos判断是否已读空整个缓冲区，若读完则等待一段时间并，回到1步，继续执行
1. 若缓冲区不空，消费者从缓冲区读取数据
1. 消费者修改readPos   

结合上面流程，再来分析我们的python实现程序，以生产者为例，我们可以发现程序中的生产者每个循环做了三件事情：   检查缓冲区是否已经写满、没有写满则写入数据、给写入指针加1。  
三个步骤任意两个步骤之间出现中断，导致两个“同时”执行都会造成竞争条件，使程序出现不可预知的后果。第一，生产者A和B“同时”检查过缓冲区判断没满，假设此时缓冲区只差1个位就满了，但有2个都判断没满，在生产者A数据写入并给指针加1后，生产者B的写入将会溢出；第二，生产者A和B“同时”写入数据，将造成向同一位置写入两个数据，造成数据被覆盖；第三，两个生产者同时给指针加一，造成指针被连续加2，造成有一个位置被跳过无法写入。   
对于消费者也可以类似推断出每个步骤出现同步都会带来竞争问题，并且实际中不同的中断还可能引发更多的竞争现象。   	怎样避免竞争条件呢？实际上凡是涉及共享内存，共享文件以及共享任何资源的情况下，都会引发类似上面的错误，所以竞争条件是一个有更普遍意义的问题，很值得我们研究一下。要避免竞争条件，关键是要找出某种途径来阻止多个进程同时读写共享的数据，实践中已经有一些有效的方法来避免竞争条件，包括锁、信号量、condition和事件，后续小节依次阐述这四种方法解决竞争条件的原理和实现方法。   
## 锁   
针对上面的问题，我们发现出现程序执行的意外主要在于不合时宜的中断，导致出现一些操作的“同步”执行，带来了竞争问题。如果我们能保证生产者每个循环做的三件事情都依次做完之后才发生中断，就不会有“同步”问题的发生了。   
当连续的几个步骤不可分割，如果分割就会引发竞争条件，这种情况下我们称这几个连续的步骤为一个原子操作。例如针对上面的问题，我们把不可分割的三个步骤定义为一个原子操作，只要能保证原子操作不被分割，就保证了不出现竞争条件。   
如何保证原子操作不被分割呢，这里就需要用到锁，在线程的原子操作执行期间锁定（或阻止）CPU的中断，待原子操作完成后才允许中断。   

本例中使用python的threading.Lock来实现锁机制，解决上述出现的竞争问题， 代码如下：  
```python
def consumer():
    t = threading.current_thread()
    global arr
    global readPos
    global onSameRound
    while 1:
        lock.acquire()
        if not (onSameRound and readPos >= writePos):
            curValue = arr[readPos]
            print('{} popped from list by {}, read position: {}'.format(
                curValue, t.name, readPos))
            readPos = countPosition(readPos)
            time.sleep(2)
        lock.release()
        time.sleep(0.01)


def producer():
    t = threading.current_thread()
    global arr
    global writePos
    global onSameRound
    while 1:
        lock.acquire()
        if not (not onSameRound and writePos >= readPos):
            integer = randint(10, 100)
            arr[writePos] = integer
            print('{} appended to list by {}, writePosition: {}'.format(
                integer, t.name, writePos))
            writePos = countPosition(writePos)
            time.sleep(1)
        lock.release()
        time.sleep(0.01)
```
代码还是两个消费者竞争，一个生产者生产数据，然后添加了一个Lock对象，在这里主要贴出了修改后的生产者消费者两个方法的代码，从中可以看出我们改进了原来的方法：  
首先在while 1循环内加了lock.acquire和lock.release两个方法，这样引入了python的Lock类，保证acquire和release之间的部分不会被中断，会是原子操作，避免了上述的竞争问题。  
其次循环体内的代码进行了修改，原来是循环睡眠等待直到标志位判断允许读取后继续后续的读取和加1操作，现在由于有了lock机制，那样做如果不满足条件，又不会被系统中断将陷入死锁当中，while循环将变成死循环。因此改进为一个if判断，如果不满足条件则直接release锁待下次再获取后重新判断。  
运行结果如下所示：  
```python
97 appended to list by pro, writePosition: 0
97 popped from list by consumer2, read position: 0
50 appended to list by pro, writePosition: 1
50 popped from list by consumer2, read position: 1
37 appended to list by pro, writePosition: 2
37 popped from list by consumer2, read position: 2
15 appended to list by pro, writePosition: 3
15 popped from list by consumer1, read position: 3
23 appended to list by pro, writePosition: 4
23 popped from list by consumer1, read position: 4
11 appended to list by pro, writePosition: 5
11 popped from list by consumer2, read position: 5
72 appended to list by pro, writePosition: 6
```
可以看出不再像之前那样两个消费者读取了同一个位置的值，而是不再发生竞争，各读取了各的值，锁解决了基本的竞争问题。  
在这里还要说明一点，如果实际运行代码，还能看到生产者平均每两秒产生一个数据，每个消费者平均每4s消费一个数据，实际上不加锁应该是每s生产一个数据，每2s消费1条数据，这说明加锁解决了竞争问题，同时不可避免的会带来效率的下降。  
这里的效率下降主要是因为生产数据全过程（以延时1s来模拟）都被包括在了锁的原子操作中，这就提醒我们可以尽量把不引起竞争问题的步骤安排在原子操作之外，以减少总体锁定的时间，提高并发运行的效率，这在多CPU，能够真正实现并行计算的环境下尤其有必要，否则多个CPU都被一个锁长时间锁定，无法发挥真正的硬件性能。   


## Condition  
针对上述使用锁的方式，我们还是觉得有不完善的地方，比如如果缓冲区已满，生产者仍然会反复去acquire这个锁，从而循环判断是否缓冲区已经不满可以写入数据了，这对系统运行性能也会带来负面影响。  
如果有一种通知机制，让生产者可以不再以轮询的方式不断获取缓冲区状态，而是什么都不做，静静等待缓冲区不满的时候接收通知，就能够提高性能并解决这个问题。Condition Variable就是这么一个机制。
### Conditon Variable  
Condition Variable 总是和某种锁绑定在一起，这个锁可以是Condition私有的，也可以和多个conditon共享同一把锁。非常实用有效的使用方法就是多个Condition共享同一把锁。绑定的锁成为了Condition的一部分，对Condition的操作会反馈到锁上面，无需（一般也不要）再直接操作锁。   
条件变量主要有四个方法，acquire用于获取当前Condition绑定的锁，release用于给当前线程释放掉锁，wait方法表示等待，即取得锁后发现继续进行工作的其他条件不满足，无法继续，便注册等待通知的事件，并释放掉锁；notify和wait是一对方法，用于在取得锁的前提下，通知正在等待的线程原来的不满足条件已满足，可以再次获取锁，一般notify之后会很快release锁，方便正在wait的线程重新acquire锁后很快能拿到锁。   
### Condition代码实现   
下面就是利用python多线程模块实现的基于Conditon的生产者消费者模型：  
```python
# coding=utf-8
import time
import threading
from random import randint


TIMEOUT = 200


def consumer():
    t = threading.current_thread()
    global arr
    global conditionCons
    global conditionPro
    while 1:
        conditionCons.acquire()
        # 由于python的安全设计，wait只等待随机长度时间
        # 因此加入循环，确保满足条件一直等待
        while len(arr) == 0:
            print('wait for ', len(arr), " by ",  t.name)
            conditionCons.wait()
        print('do for ', len(arr), " by ", t.name)
        curValue = arr.pop()
        print('{} popped from list by {}, read position: {}'.format(
            curValue, t.name, len(arr)))
        time.sleep(2)
        conditionPro.notify()
        conditionCons.release()
        time.sleep(0.1)


def producer():
    t = threading.current_thread()
    global arr
    global conditionCons
    global conditionPro
    while 1:
        conditionPro.acquire()
        # 由于python的安全设计，wait只等待随机长度时间
        # 因此加入循环，确保满足条件一直等待
        while len(arr) == 10:
            conditionPro.wait()
        integer = randint(10, 100)
        arr.append(integer)
        print('{} appended to list by {}, writePosition: {}'.format(
            integer, t.name, len(arr)))
        time.sleep(1)
        print('do for ', len(arr), " by ", t.name)
        conditionCons.notify(1)
        conditionPro.release()
        time.sleep(0.1)


stackLength = 10
arr = []
threads = []
lock = threading.Lock()
conditionCons = threading.Condition(lock)
conditionPro = threading.Condition(lock)

t = threading.Thread(name="consumer1", target=consumer)
t.daemon = True
t.start()
threads.append(t)


t2 = threading.Thread(name="consumer2", target=consumer)
t2.daemon = True
t2.start()
threads.append(t2)

p = threading.Thread(name='pro', target=producer)
p.daemon = True
p.start()
threads.append(p)

time.sleep(100)
```  
上述代码利用Condition改进了锁的实现效果，我们设置了两个Condition，绑定了同一把锁，所以生产者和消费者的整体逻辑还是由一把锁来控制。下面介绍一下具体流程，以生产者为例，conditionPro获取锁，然后判断缓冲区是否已满，如果已满则等待缓冲区不满的通知，如果缓冲区未满则开始生产数据、写入数据的流程、给标志位加一的流程。  
如果生产者进入等待状态，只有conditionPro.notify方法能够再次唤醒这个线程，但是唤醒的前提是缓冲区未满，所以把这个唤醒的时间点放在消费者消费一个数据结束的时候，调用生产者conditionPro的notify方法，从而唤醒生产者线程，开始生产数据。  
可以看到这个逻辑同样保证了三步操作的原子性，同时避免了不断轮询检查标志位空满，直接等待事件通知，提高了效率，运行结果如下所示：  
```python
46 appended to list by pro, writePosition: 1
46 popped from list by consumer1, read position: 0
72 appended to list by pro, writePosition: 1
72 popped from list by consumer1, read position: 0
59 appended to list by pro, writePosition: 1
59 popped from list by consumer1, read position: 0
50 appended to list by pro, writePosition: 1
50 popped from list by consumer1, read position: 0
37 appended to list by pro, writePosition: 1
37 popped from list by consumer2, read position: 0
49 appended to list by pro, writePosition: 1
49 popped from list by consumer2, read position: 0
45 appended to list by pro, writePosition: 1
45 popped from list by consumer2, read position: 0
```
可以看出没有出现竞争问题

。。。。。。。。。。。。。。。。

## 信号量   
锁是解决竞争问题的最直观的办法，通过锁定中断，保证同时只有一个线程同时工作并完成原子操作，确保了不会发生意外。但是如上所示的这种完全排他性的锁，也称为悲观锁，实际上在锁发挥作用期间阻断了并发运行的可能性，降低了整个进程的运行效率。另外，我们可以看到为了让锁真正发挥作用，原子操作涵盖了整个三步（其中的sleep时间用于指代生产和消费数据的实际业务会耗费的时间），用时较长，在这种情况下，整个代码的并行或并发实际上无法有效实现。   
实际上目前还有其他一些办法用于解决竞争问题，比如锁的层面上除了悲观锁，还有乐观锁等很多种锁的算法。本小节不再继续对锁进行拓展，有兴趣的读者可以自己搜索一下，本节介绍另一个在锁的思想基础上开发的算法：信号量。   
### 概念和分析
信号量（semaphore）是一种更高级的同步机制，mutex可以说是semaphore在仅取值0/1时的特例。Semaphore可以有更多的取值空间，用来实现更加复杂的同步，而不单单是线程间互斥。  
来自 <https://www.zhihu.com/question/39850927/answer/91598103>   
信号量通过一个计数器控制对共享资源的访问，信号量的值是一个非负整数，所有通过它的线程都会将该整数减一。如果计数器大于0，则访问被允许，计数器减1；如果为0，则访问被禁止，所有试图通过它的线程都将处于等待状态。  
计数器计算的结果是允许访问共享资源的通行证。因此，为了访问共享资源，线程必须从信号量得到通行证， 如果该信号量的计数大于0，则此线程获得一个通行证，这将导致信号量的计数递减，否则，此线程将阻塞直到获得一个通行证为止。当此线程不再需要访问共享资源时，它释放该通行证，这导致信号量的计数递增，如果另一个线程等待通行证，则那个线程将在那时获得通行证。  
来自 <https://blog.csdn.net/shaohua_lv/article/details/70257100>   
### 通过信号量改进上述的问题    
为了解决上述锁定时间过长，严重降低运行效率的问题，我们可以引入信号量，因为信号量依据其设计机制，可以允许限定范围内的多个线程同时取得运行的权利，可以有效提高系统的并发或并行运行效率。  
具体引入信号量后的生产者消费者代码如下所示：    
```python
def consumer():
    t = threading.current_thread()
    global arr
    global readPos
    while 1:
        readSemaphore.acquire()
        lock.acquire()
        curValue = arr[readPos]
        print('{} popped from list by {}, read position: {}'.format(
            curValue, t.name, readPos))
        readPos = countPosition(readPos)
        lock.release()
        time.sleep(2)
        writeSemaphore.release()


def producer():
    t = threading.current_thread()
    global arr
    global writePos
    while 1:
        writeSemaphore.acquire()
        integer = randint(10, 100)
        lock.acquire()
        arr[writePos] = integer
        print('{} appended to list by {}, writePosition: {}'.format(
            integer, t.name, writePos))
        writePos = countPosition(writePos)
        lock.release()
        time.sleep(1)
        readSemaphore.release()
```
如上所示，我们建立了readSemaphore和writeSemaphore两个信号量，一个记录当前缓冲区是否已空（不能读取）或者已满（不能写入），这样之前写的判断是否读空或写入溢出的代码都删掉。在生产者和消费者线程中，我们把判断是否能写入和读取的逻辑替换成了信号量的获取和释放，这样我们利用信号量来管理我们对缓冲区标志位的控制工作。  
如上所示，生产者首先获取写入信号量，能获取则生产写入数据并给标志位加1，给读取信号量释放一个位，这样读取那边就多了一个读取位；消费者线程恰好相反。通过这样的改进之后，我们可以把锁挪到信号量相关逻辑的内部，如上所示，仍然以生产者为例，这时候标志位判断已经交给信号量了，我们让锁只控制数据的写入和标志位的加1这两步就可以了，标志位判断和数据生产等业务逻辑（integer = randint(10, 100) 和time.sleep(1)）都被移到了锁外面，确保这些步骤都能并发或并行进行，对系统运行效率有很大提高。  
另外我们无需担心锁不控制标志位判断会带来前述的重复判断带来的缓冲区溢出问题，因为信号量本身的操作能保证自身的原子性，aquire()运行后会立刻给内部控制位减1，不会被中断。 
下面是本例运行结果，可以看出仍然保证了结果无误，如果实际运行能看到运行速度明显比锁的方案要快，和未加锁时速度基本无差别：  
```python
11 popped from list by consumer2, read position: 3
52 appended to list by pro, writePosition: 5
79 popped from list by consumer1, read position: 4
76 appended to list by pro, writePosition: 6
52 popped from list by consumer2, read position: 5
83 appended to list by pro, writePosition: 7
76 popped from list by consumer1, read position: 6
61 appended to list by pro, writePosition: 8
83 popped from list by consumer2, read position: 7
27 appended to list by pro, writePosition: 9
61 popped from list by consumer1, read position: 8
24 appended to list by pro, writePosition: 0
27 popped from list by consumer2, read position: 9
63 appended to list by pro, writePosition: 1
24 popped from list by consumer1, read position: 0
```


## Event